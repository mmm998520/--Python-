{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: KERAS_BACKEND=tensorflow\n"
     ]
    }
   ],
   "source": [
    "%env KERAS_BACKEND=tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,y_train),(x_test,y_test)=mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 整理資料格式\n",
    "CNN讀的是照片，所以不用把28*28的圖改成728\n",
    "\n",
    "但是它需要rgb三層維度，或是使用灰階，使用灰階也要多宣告一個維度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x_train\n",
    "x_train = x_train.reshape(60000,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import (Dense,\n",
    "                          Activation,\n",
    "                          Flatten,\n",
    "                          Conv2D,\n",
    "                          MaxPooling2D)\n",
    "from keras.optimizers import Adam\n",
    "#from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建構神經網路"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 卷積、池化識別圖案特色\n",
    "#### Conv2D -> relu -> MaxPooling2D\n",
    "卷積 -> 激活 -> 池化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(32,(3,3),padding='same',input_shape=(28,28,1)))\n",
    "model.add(Activation('relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "#model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(64,(3,3),padding = 'same'))\n",
    "model.add(Activation('relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "#model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(128,(3,3),padding = 'same'))\n",
    "model.add(Activation('relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "#model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 轉到全連接層學習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())\n",
    "model.add(Dense(200))\n",
    "model.add(Activation('relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 組裝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer=Adam(lr=0.0001),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 128)         73856     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 200)               230600    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                2010      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 325,282\n",
      "Trainable params: 325,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Param = （輸入數據維度+1）* 神經元個數\n",
    "\n",
    "32個3*3的 filter，會有9個維度、32個神經元"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "320"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((3*3)+1)*32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "600/600 [==============================] - 34s 56ms/step - loss: 0.7052 - accuracy: 0.8742\n",
      "Epoch 2/12\n",
      "600/600 [==============================] - 34s 57ms/step - loss: 0.1145 - accuracy: 0.9662\n",
      "Epoch 3/12\n",
      "600/600 [==============================] - 34s 56ms/step - loss: 0.0708 - accuracy: 0.9779\n",
      "Epoch 4/12\n",
      "600/600 [==============================] - 35s 58ms/step - loss: 0.0469 - accuracy: 0.9853\n",
      "Epoch 5/12\n",
      "600/600 [==============================] - 35s 58ms/step - loss: 0.0355 - accuracy: 0.9885\n",
      "Epoch 6/12\n",
      "600/600 [==============================] - 35s 58ms/step - loss: 0.0260 - accuracy: 0.9913\n",
      "Epoch 7/12\n",
      "600/600 [==============================] - 35s 58ms/step - loss: 0.0222 - accuracy: 0.9926\n",
      "Epoch 8/12\n",
      "600/600 [==============================] - 35s 58ms/step - loss: 0.0185 - accuracy: 0.9941\n",
      "Epoch 9/12\n",
      "600/600 [==============================] - 36s 59ms/step - loss: 0.0138 - accuracy: 0.9955\n",
      "Epoch 10/12\n",
      "600/600 [==============================] - 35s 58ms/step - loss: 0.0136 - accuracy: 0.9955\n",
      "Epoch 11/12\n",
      "600/600 [==============================] - 35s 59ms/step - loss: 0.0111 - accuracy: 0.9959\n",
      "Epoch 12/12\n",
      "600/600 [==============================] - 34s 57ms/step - loss: 0.0087 - accuracy: 0.9971\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x28a522e1fc8>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,batch_size=100,epochs=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0609 - accuracy: 0.9853\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test.reshape(10000,28,28,1),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.06088158115744591\n",
      "acc: 0.9853000044822693\n"
     ]
    }
   ],
   "source": [
    "print('loss:',score[0])\n",
    "print('acc:',score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "open('cnn_write_architecture_test.json','w').write(model_json)\n",
    "model.save_weights('cnn_write_weight_test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-28-ff1a64576fd3>:1: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    }
   ],
   "source": [
    "predict = model.predict_classes(x_test.reshape(10000,28,28,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pick = np.random.randint(0,10000,5)\n",
    "\n",
    "for i in range(5):\n",
    "    plt.subplot(1,5,i+1)\n",
    "    plt.imshow(x_test[pick[i]].reshape(28,28),cmap='Greys')\n",
    "    plt.title(predict[pick[i]])\n",
    "    plt.axis(\"off\")\n",
    "    print(y_test[pick[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
